<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Ai on teleported.in</title>
    <link>http://teleported.in/tags/ai/</link>
    <description>Recent content in Ai on teleported.in</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Mon, 02 Oct 2017 23:27:27 -0400</lastBuildDate>
    
	<atom:link href="http://teleported.in/tags/ai/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>An intuitive explaination of Batch Normalization</title>
      <link>http://teleported.in/posts/batch-normalization-explained/</link>
      <pubDate>Mon, 02 Oct 2017 23:27:27 -0400</pubDate>
      
      <guid>http://teleported.in/posts/batch-normalization-explained/</guid>
      <description>Test.</description>
    </item>
    
    <item>
      <title>Simulated Annealing simply explained</title>
      <link>http://teleported.in/posts/simulated-annealing-metaphor/</link>
      <pubDate>Wed, 24 May 2017 00:27:27 -0400</pubDate>
      
      <guid>http://teleported.in/posts/simulated-annealing-metaphor/</guid>
      <description>(I had explained Simulated Annealing to someone on Udacity forum. Here was the conversation.)
Can someone please explain simulated annealing to me with an example not using schedule(t) or Temperature? The video and book aren&#39;t too great at the explanation.
Image Source: Wikipedia
Let me give it a shot.
If I have to explain it without using technical terms, I will describe it like this:
Imagine that you are a dot on a 2D graph of maximas and minimas (peaks and valleys).</description>
    </item>
    
    <item>
      <title>Analysing AlphaGo</title>
      <link>http://teleported.in/posts/analysing-alphago/</link>
      <pubDate>Fri, 12 May 2017 23:27:27 -0400</pubDate>
      
      <guid>http://teleported.in/posts/analysing-alphago/</guid>
      <description>(I wrote this piece as part of an assignment for Udacity&amp;rsquo;s AI Nanodegree program. The assignment was to summarize the AlphaGo paper in a page)
Introduction Go is a two player, turn taking, deterministic game of perfect information. Two main factors make Go very complex to solve:
 Go has an average branching factor ‘b’ of ~250 options per node (chess ~35) Go has an average depth ‘d’ of ~150 moves (chess ~80)  These factos make the state space of Go (bd) enormous to search end to end using traditional techniques.</description>
    </item>
    
    <item>
      <title>Visualising AI Search Algorithms</title>
      <link>http://teleported.in/posts/ai-search-algorithms/</link>
      <pubDate>Fri, 05 May 2017 23:27:27 -0400</pubDate>
      
      <guid>http://teleported.in/posts/ai-search-algorithms/</guid>
      <description>Search algorithms help find the correct sequence of actions in a search space, to reach a goal state. The sequence of actions might be:
 Sequence in which cities are to be visited to travel from a source to a destination under a given cost function (shortest path, cheapest fare etc.) Sequence in which an agent should play moves in a game (chess, tic tac toe, pacman etc.) to win a board game Sequence in which a robot arm should solder components on a PCB under a given cost function (e.</description>
    </item>
    
  </channel>
</rss>